{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Packing Surrogate Model\n",
    "\n",
    "Here, we train a surrogate model for the particle packing simulations. We capture the\n",
    "presence of failed simulations, the packing fractions for two different algorithms, and\n",
    "the corresponding runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from os import path, getcwd\n",
    "import json\n",
    "\n",
    "# attempted use of skl2onnx to convert to onnx failing due to protobuf error\n",
    "# https://github.com/onnx/onnx/issues/4469\n",
    "\n",
    "# from skl2onnx import convert_sklearn\n",
    "# from skl2onnx.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = True\n",
    "\n",
    "data_dir = path.join(\"..\", \"..\", \"data\", \"processed\", \"particle_packing\")\n",
    "model_dir = path.join(\"..\", \"..\", \"models\", \"particle_packing\")\n",
    "\n",
    "if dummy:\n",
    "    model_dir = path.join(model_dir, \"dummy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_filter = pd.read_csv(path.join(data_dir, \"sobol_probability_filter.csv\"))\n",
    "sobol_reg = pd.read_csv(path.join(data_dir, \"sobol_regression.csv\"))\n",
    "\n",
    "if dummy:\n",
    "    sobol_filter = sobol_filter.head(100)\n",
    "    sobol_reg = sobol_reg.head(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define f(x) to calc mae scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument for rfr_mae, X_array, y_array, model_name to save model as .pkl\n",
    "def rfr_mae(X_array, y_array, model_name_stem, random_state=13):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    mae_scores = []\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_array)):\n",
    "        X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "        y_train, y_test = y_array[train_index], y_array[test_index]\n",
    "        y_test = y_test.tolist()\n",
    "\n",
    "        model = RandomForestRegressor(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test).tolist()\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        y_trues.append(y_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mae_scores.append(mae)\n",
    "        # save model as .pkl\n",
    "        joblib.dump(model, f\"{model_name_stem}_{i}.pkl\")\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)\n",
    "    print(f\"MAE for fba_isna_prob: {avg_mae:.4f} +/- {std_mae:.4f}\")\n",
    "    results = {\"mae\": mae_scores, \"y_pred\": y_preds, \"y_true\": y_trues}\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = [\n",
    "    \"mu1_div_mu3\",\n",
    "    \"mu2_div_mu3\",\n",
    "    \"std1\",\n",
    "    \"std2\",\n",
    "    \"std3\",\n",
    "    \"comp1\",\n",
    "    \"comp2\",\n",
    "    \"num_particles\",\n",
    "    \"safety_factor\",\n",
    "]\n",
    "\n",
    "fba_isna_prob_features = common_features\n",
    "ls_isna_prob_features = common_features\n",
    "fba_features = common_features + [\"fba_rank\"]\n",
    "ls_features = common_features + [\"ls_rank\"]\n",
    "fba_time_s_features = common_features + [\"fba_time_s_rank\"]\n",
    "ls_time_s_features = common_features + [\"ls_time_s_rank\"]\n",
    "\n",
    "lst_of_features = [fba_isna_prob_features, ls_isna_prob_features, fba_features, ls_features, fba_time_s_features, ls_time_s_features]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Filter\n",
    "### fba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold cross-validation iterator\n",
    "X_array_fba_isna_prob = sobolPF_fba_isna_prob.to_numpy()\n",
    "y_array_fba_isna_prob = fba_isna_prob.to_numpy().ravel()\n",
    "\n",
    "# This is the trained model on As a function of mu1_div_mu3, mu2_div_mu3, std1, std2,\n",
    "# std3, comp1, comp2, num_particles, safety_factor\n",
    "\n",
    "fba_isna_model_stem = path.join(model_dir, \"spf_fba_isna_prob\")\n",
    "fba_isna_results = rfr_mae(\n",
    "    X_array_fba_isna_prob, y_array_fba_isna_prob, fba_isna_model_stem\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test loading the pickled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [0.13195144 0.01562704 0.01174009 0.05571678 0.07210101]\n",
      "1: [0.1350979  0.         0.01711422 0.00272727 0.05094561]\n",
      "2: [0.11676185 0.00820513 0.02761111 0.055      0.07425952]\n",
      "3: [0.15478488 0.02769231 0.01432984 0.05675408 0.08220396]\n",
      "4: [0.12868454 0.01942308 0.05485354 0.05918803 0.07221212]\n"
     ]
    }
   ],
   "source": [
    "test_data = X_array_fba_isna_prob[:5]\n",
    "for i in range(5):\n",
    "    model = joblib.load(f\"{fba_isna_model_stem}_{i}.pkl\")\n",
    "    print(f\"{i}: {model.predict(test_data)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for fba_isna_prob: 0.1782 +/- 0.0383\n"
     ]
    }
   ],
   "source": [
    "sobolPF_ls_isna_prob = sobol_filter[fba_isna_prob_features]\n",
    "ls_isna_prob = sobol_filter[[\"ls_isna_prob\"]]\n",
    "\n",
    "X_array_ls_isna_prob = sobolPF_ls_isna_prob.to_numpy()\n",
    "y_array_ls_isna_prob = ls_isna_prob.to_numpy().ravel()\n",
    "\n",
    "# ls_isna_model_stem = path.join(model_dir, \"spf_ls_isna_prob\")\n",
    "# ls_isna_results = rfr_mae(\n",
    "#     X_array_ls_isna_prob, y_array_ls_isna_prob, ls_isna_model_stem\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packing Fraction Models\n",
    "### fba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for fba_isna_prob: 0.0082 +/- 0.0015\n"
     ]
    }
   ],
   "source": [
    "sobol_reg_fba = sobol_reg.dropna(subset=[\"fba\"])\n",
    "X_array_fba = sobol_reg_fba[fba_features].to_numpy()\n",
    "y_array_fba = sobol_reg_fba[\"fba\"].to_numpy().ravel()\n",
    "\n",
    "fba_model_stem = path.join(model_dir, \"sobol_reg_fba\")\n",
    "fba_results = rfr_mae(X_array_fba, y_array_fba, fba_model_stem)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for fba_isna_prob: 0.0152 +/- 0.0029\n"
     ]
    }
   ],
   "source": [
    "sobol_reg_ls = sobol_reg.dropna(subset=[\"ls\"])\n",
    "X_array_ls = sobol_reg_ls[ls_features].to_numpy()\n",
    "y_array_ls = sobol_reg_ls[\"ls\"].to_numpy().ravel()\n",
    "\n",
    "ls_model_path = path.join(model_dir, \"sobol_reg_ls\")\n",
    "ls_results = rfr_mae(X_array_ls, y_array_ls, ls_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Models\n",
    "No NaNs in the time values.\n",
    "### fba_time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for fba_isna_prob: 0.0435 +/- 0.0152\n"
     ]
    }
   ],
   "source": [
    "X_array_ls_time_s = sobol_reg[ls_time_s_features].to_numpy()\n",
    "fba_time_s = sobol_reg[[\"fba_time_s\"]]\n",
    "y_array_fba_time_s = fba_time_s.to_numpy().ravel()\n",
    "\n",
    "fba_time_s_model_stem = path.join(model_dir, \"sobol_reg_fba_time_s\")\n",
    "fba_time_s_results = rfr_mae(\n",
    "    X_array_ls_time_s, y_array_fba_time_s, fba_time_s_model_stem\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ls_time_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for fba_isna_prob: 2.2572 +/- 0.5052\n"
     ]
    }
   ],
   "source": [
    "X_array_ls_time_s = sobol_reg[ls_time_s_features].to_numpy()\n",
    "ls_time_s = sobol_reg[[\"ls_time_s\"]]\n",
    "y_array_ls_time_s = ls_time_s.to_numpy().ravel()\n",
    "\n",
    "ls_time_s_model_stem = path.join(model_dir, \"sobol_reg_ls_time_s\")\n",
    "ls_time_s_results = rfr_mae(X_array_ls_time_s, y_array_ls_time_s, ls_time_s_model_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder where is the data and what is it saving\n",
    "main_results = {\n",
    "    \"fba_isna_prob\": fba_isna_results,\n",
    "    \"ls_isna_prob\": ls_isna_results,\n",
    "    \"fba\": fba_results,\n",
    "    \"ls\": ls_results,\n",
    "    \"fba_time_s\": fba_time_s_results,\n",
    "    \"ls_time_s\": ls_time_s_results,\n",
    "}\n",
    "with open(path.join(data_dir, \"model_metadata.json\"), \"w\") as f:\n",
    "    json.dump(main_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = {\n",
    "    \"fba_isna_prob\": fba_isna_model_stem,\n",
    "    \"ls_isna_prob\": ls_isna_model_stem,\n",
    "    \"fba\": fba_model_stem,\n",
    "    \"ls\": ls_model_path,\n",
    "    \"fba_time_s\": fba_time_s_model_stem,\n",
    "    \"ls_time_s\": ls_time_s_model_stem,\n",
    "}\n",
    "models = {}\n",
    "for key, model_path in model_paths.items():\n",
    "    models[key] = [joblib.load(f\"{model_path}_{i}.pkl\") for i in range(5)]\n",
    "\n",
    "with open(path.join(model_dir, \"cross_validation_models.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(models, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sobol_filter = pd.read_csv(path.join(data_dir, \"sobol_probability_filter.csv\"))\n",
    "sobol_reg = pd.read_csv(path.join(data_dir, \"sobol_regression.csv\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A trained dummy model \n",
    "## 6 keys in the dictionary, each key is a value of a label, and its value pair is the trained model.\n",
    "## this trained model is stored in the models folder with the pickle file name \"trained_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = True\n",
    "if dummy:\n",
    "    sobol_filter = sobol_filter.head(100)\n",
    "    sobol_reg = sobol_reg.head(100)\n",
    "sobol_filter\n",
    "sobol_reg\n",
    "\n",
    "#sobol_reg feature list to train on\n",
    "sobol_reg_features_lst = ['mu1_div_mu3', 'mu2_div_mu3', 'std1', 'std2', 'std3', 'comp1', 'comp2', 'num_particles', 'safety_factor', 'fba_rank', 'ls_rank', 'fba_time_s_rank', 'ls_time_s_rank']\n",
    "#sobol_reg label list to train on \n",
    "sobol_reg_target_lst = ['fba', 'ls', 'fba_time_s', 'ls_time_s']\n",
    "\n",
    "#sobol_filter feature list to train on\n",
    "sobol_filter_features_lst = ['mu1_div_mu3', 'mu2_div_mu3', 'std1', 'std2', 'std3', 'comp1', 'comp2', 'num_particles', 'safety_factor']\n",
    "#sobol_filter label list to train on\n",
    "sobol_filter_target_lst = ['fba_isna_prob', 'ls_isna_prob']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "#Sobol_reg feature and target lists\n",
    "sobol_reg_features_lst = ['mu1_div_mu3', 'mu2_div_mu3', 'std1', 'std2', 'std3', 'comp1', 'comp2', 'num_particles', 'safety_factor', 'fba_rank', 'ls_rank', 'fba_time_s_rank', 'ls_time_s_rank']\n",
    "sobol_reg_target_lst = ['fba', 'ls', 'fba_time_s', 'ls_time_s']\n",
    "\n",
    "#Sobol_filter feature and target lists\n",
    "sobol_filter_features_lst = ['mu1_div_mu3', 'mu2_div_mu3', 'std1', 'std2', 'std3', 'comp1', 'comp2', 'num_particles', 'safety_factor']\n",
    "sobol_filter_target_lst = ['fba_isna_prob', 'ls_isna_prob']\n",
    "\n",
    "\n",
    "\n",
    "def train_and_pickle(df1, df2,feature_lst_df1,feature_lst_df2,label_lst_df1, label_lst_df2):\n",
    "    models = {}\n",
    "    \n",
    "    for label in label_lst_df1:\n",
    "        X = df1[feature_lst_df1]\n",
    "        y = df1[label]\n",
    "        \n",
    "        model = RandomForestRegressor(random_state=13)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        models[label] = model\n",
    "        \n",
    "    for label in label_lst_df2:\n",
    "        X = df2[feature_lst_df2]\n",
    "        y = df2[label]\n",
    "        \n",
    "        model = RandomForestRegressor(random_state=13)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        models[label] = model\n",
    "        \n",
    "    joblib.dump(models, \"trained_model.pkl\")    \n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fba_isna_prob': RandomForestRegressor(random_state=13),\n",
       " 'ls_isna_prob': RandomForestRegressor(random_state=13),\n",
       " 'fba': RandomForestRegressor(random_state=13),\n",
       " 'ls': RandomForestRegressor(random_state=13),\n",
       " 'fba_time_s': RandomForestRegressor(random_state=13),\n",
       " 'ls_time_s': RandomForestRegressor(random_state=13)}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobol_filter_cln = sobol_filter.dropna()\n",
    "sobol_reg_cln = sobol_reg.dropna()\n",
    "train_and_pickle(sobol_filter_cln, sobol_reg_cln, sobol_filter_features_lst, sobol_reg_features_lst, sobol_filter_target_lst, sobol_reg_target_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Using Trained On All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run and save 6 models trained on all the data (not cross-validation) as a single .pkl\n",
    "# file\n",
    "# save it to a single .pkl file as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of arrays of x_arrays and y_arrays\n",
    "# X_arrays = [\n",
    "#     X_array_fba_isna_prob,\n",
    "#     X_array_ls_isna_prob,\n",
    "#     X_array_fba,\n",
    "#     X_array_ls,\n",
    "#     X_array_ls_time_s,\n",
    "#     X_array_ls_time_s,\n",
    "# ]\n",
    "# y_arrays = [\n",
    "#     y_array_fba_isna_prob,\n",
    "#     y_array_ls_isna_prob,\n",
    "#     y_array_fba,\n",
    "#     y_array_ls,\n",
    "#     y_array_fba_time_s,\n",
    "#     y_array_ls_time_s,\n",
    "# ]\n",
    "\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=13)\n",
    "# trained_model_fba_isna_prob = rf.fit(X_array_fba_isna_prob, y_array_fba_isna_prob)\n",
    "# with open(path.join(model_dir, \"trained_model_fba_isna_prob.pkl\"), \"wb\") as f:\n",
    "#     joblib.dump(trained_model_fba_isna_prob, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code graveyard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Average MAE for fba_isna_prob\",rfr_mae(X_array_fba_isna_prob, y_array_fba_isna_prob,'fba_isna_prob.pkl'))\n",
    "\n",
    "# load trained model\n",
    "# loaded_model = joblib.load('fba_isna_prob_model.pkl')\n",
    "\n",
    "# Save the model\n",
    "# with open('../models/fba_isna_prob.pkl', 'wb') as f:\n",
    "#     pickle.dump(model, f)\n",
    "\n",
    "# # Load the model\n",
    "# with open('path/to/save/model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_sobol_filter = \"https://zenodo.org/record/7513019/files/sobol_probability_filter.csv\"\n",
    "# sobol_filter = pd.read_csv(url_sobol_filter)\n",
    "\n",
    "# url_sobol_reg = \"https://zenodo.org/record/7513019/files/sobol_regression.csv\"\n",
    "# sobol_reg = pd.read_csv(url_sobol_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()\n",
    "# os.chdir(\"../data/raw\")\n",
    "\n",
    "# sobol_filter.to_csv('sobol_filter.csv', index=False)\n",
    "\n",
    "# sobol_reg.to_csv('sobol_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in sobol_regression.csv\n",
    "# url_sobol_reg = \"https://zenodo.org/record/7513019/files/sobol_regression.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sobol_reg_x = sobol_reg[\n",
    "#     [\n",
    "#         \"mu1_div_mu3\",\n",
    "#         \"mu2_div_mu3\",\n",
    "#         \"std1\",\n",
    "#         \"std2\",\n",
    "#         \"std3\",\n",
    "#         \"comp1\",\n",
    "#         \"comp2\",\n",
    "#         \"num_particles\",\n",
    "#         \"safety_factor\",\n",
    "#         \"fba_rank\",\n",
    "#         \"ls_rank\",\n",
    "#         \"fba_time_s_rank\",\n",
    "#         \"ls_time_s_rank\",\n",
    "#     ]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(sobol_reg_x))\n",
    "# print(len(fba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"Average MAE for ls_time_s\",\n",
    "#     rfr_mae(X_array_fba_time_s, y_array_ls_time_s, \"sobol_reg_ls_time_s.pkl\"),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parse data for target \"fba_isna_prob\"\n",
    "# fba_isna_prob = sobol_filter[\"fba_isna_prob\"]\n",
    "# sobolPF_fba_isna_prob = sobol_filter.drop([\"ls_isna_prob\", \"fba_isna_prob\"], axis=1)\n",
    "# fba_isna_prob = fba_isna_prob.to_frame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6653e4c60a5100456682de71b845560e4dadae9c4ba352325d2184e42e2b85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
