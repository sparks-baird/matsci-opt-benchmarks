{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrabNet Hyperparameter Surrogate Model\n",
    "\n",
    "Here, we train a surrogate model for the CrabNet hyperparameter optimization on Matbench\n",
    "datasets. We capture average model performance (MAE and RMSE) as well as model\n",
    "complexity and runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from os import path\n",
    "import json\n",
    "\n",
    "# attempted use of skl2onnx to convert to onnx failing due to protobuf error\n",
    "# https://github.com/onnx/onnx/issues/4469\n",
    "\n",
    "# from skl2onnx import convert_sklearn\n",
    "# from skl2onnx.common.data_types import FloatTensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "dummy = False\n",
    "\n",
    "task_name = \"crabnet_hyperparameter\"\n",
    "\n",
    "data_dir = path.join(\"..\", \"..\", \"data\", \"processed\", task_name)\n",
    "model_dir = path.join(\"..\", \"..\", \"models\", task_name)\n",
    "\n",
    "if dummy:\n",
    "    model_dir = path.join(model_dir, \"dummy\")\n",
    "    \n",
    "cv_model_dir = path.join(model_dir, \"cv\")\n",
    "\n",
    "Path(model_dir).mkdir(exist_ok=True, parents=True) # technically redundant\n",
    "Path(cv_model_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobol_reg = pd.read_csv(path.join(data_dir, \"sobol_regression.csv\"))\n",
    "\n",
    "if dummy:\n",
    "    data_dir = path.join(data_dir, \"dummy\")\n",
    "    sobol_reg = sobol_reg.head(100)\n",
    "    \n",
    "Path(data_dir).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Random Forest Classifier -- Convert Categorical Data to Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias_ohe = pd.get_dummies(sobol_reg[\"bias\"], prefix=\"bias\")\n",
    "criterion_ohe = pd.get_dummies(sobol_reg[\"criterion\"], prefix=\"criterion\")\n",
    "elemprop_ohe = pd.get_dummies(sobol_reg[\"elem_prop\"], prefix=\"elem_prop\")\n",
    "hardware_ohe = pd.get_dummies(sobol_reg[\"hardware\"], prefix=\"hardware\")\n",
    "\n",
    "sobol_reg[\"bias\"] = sobol_reg[\"bias\"].astype(int)\n",
    "\n",
    "sobol_reg = pd.concat([sobol_reg, criterion_ohe, elemprop_ohe, hardware_ohe], axis=1)\n",
    "\n",
    "sobol_reg.drop(columns=[\"criterion\", \"elem_prop\", \"hardware\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define f(x) to calc mae scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument for rfr_mae, X_array, y_array, model_name to save model as .pkl\n",
    "def rfr_group_mae(\n",
    "    X_array, y_array, group_array, model_name_stem, objective_name, random_state=13\n",
    "):\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    mae_scores = []\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    for i, (train_index, test_index) in enumerate(\n",
    "        kf.split(X_array, y_array, group_array)\n",
    "    ):\n",
    "        X_train, X_test = X_array[train_index], X_array[test_index]\n",
    "        y_train, y_test = y_array[train_index], y_array[test_index]\n",
    "        y_test = y_test.tolist()\n",
    "\n",
    "        model = RandomForestRegressor(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test).tolist()\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        y_trues.append(y_test)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mae_scores.append(mae)\n",
    "        # save model as .pkl\n",
    "        joblib.dump(model, f\"{model_name_stem}_{i}.pkl\", compress=7)\n",
    "\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)\n",
    "\n",
    "    print(f\"MAE for {objective_name}: {avg_mae:.4f} +/- {std_mae:.4f}\")\n",
    "    results = {\"mae\": mae_scores, \"y_pred\": y_preds, \"y_true\": y_trues}\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = [\n",
    "    \"N\",\n",
    "    \"alpha\",\n",
    "    \"d_model\",\n",
    "    \"dim_feedforward\",\n",
    "    \"dropout\",\n",
    "    \"emb_scaler\",\n",
    "    \"eps\",\n",
    "    \"epochs_step\",\n",
    "    \"fudge\",\n",
    "    \"heads\",\n",
    "    \"k\",\n",
    "    \"lr\",\n",
    "    \"pe_resolution\",\n",
    "    \"ple_resolution\",\n",
    "    \"pos_scaler\",\n",
    "    \"weight_decay\",\n",
    "    \"batch_size\",\n",
    "    \"out_hidden4\",\n",
    "    \"betas1\",\n",
    "    \"betas2\",\n",
    "    \"train_frac\",\n",
    "    \"bias\",\n",
    "    \"criterion_RobustL1\",\n",
    "    \"criterion_RobustL2\",\n",
    "    \"elem_prop_magpie\",\n",
    "    \"elem_prop_mat2vec\",\n",
    "    \"elem_prop_onehot\",\n",
    "    \"hardware_2080ti\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Surrogate Models\n",
    "#### no NaN values\n",
    "### mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for mae: 0.0217 +/- 0.0004\n"
     ]
    }
   ],
   "source": [
    "mae_features = common_features + [\"mae_rank\"]\n",
    "\n",
    "X_array_mae = sobol_reg[mae_features].to_numpy()\n",
    "y_array_mae = sobol_reg[[\"mae\"]].to_numpy().ravel()\n",
    "\n",
    "sobol_reg_mae_group = (\n",
    "    sobol_reg[common_features]\n",
    "    .round(6)\n",
    "    .apply(lambda row: \"_\".join(row.values.astype(str)), axis=1)\n",
    ")\n",
    "\n",
    "mae_model_stem = path.join(model_dir, \"sobol_reg_mae\")\n",
    "mae_results = rfr_group_mae(\n",
    "    X_array_mae, y_array_mae, sobol_reg_mae_group, mae_model_stem, \"mae\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for rmse: 0.0265 +/- 0.0004\n"
     ]
    }
   ],
   "source": [
    "rmse_features = common_features + [\"rmse_rank\"]\n",
    "\n",
    "X_array_rmse = sobol_reg[rmse_features].to_numpy()\n",
    "y_array_rmse = sobol_reg[[\"rmse\"]].to_numpy().ravel()\n",
    "\n",
    "sobol_reg_rmse_group = (\n",
    "    sobol_reg[common_features]\n",
    "    .round(6)\n",
    "    .apply(lambda row: \"_\".join(row.values.astype(str)), axis=1)\n",
    ")\n",
    "\n",
    "rmse_model_stem = path.join(model_dir, \"sobol_reg_rmse\")\n",
    "rmse_results = rfr_group_mae(\n",
    "    X_array_rmse, y_array_rmse, sobol_reg_rmse_group, rmse_model_stem, \"rmse\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model size ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for model_size: 317796.8646 +/- 6005.9939\n"
     ]
    }
   ],
   "source": [
    "model_size_features = common_features\n",
    "\n",
    "X_array_model_size = sobol_reg[model_size_features].to_numpy()\n",
    "y_array_model_size = sobol_reg[[\"model_size\"]].to_numpy().ravel()\n",
    "\n",
    "sobol_reg_model_size_group = (\n",
    "    sobol_reg[common_features]\n",
    "    .round(6)\n",
    "    .apply(lambda row: \"_\".join(row.values.astype(str)), axis=1)\n",
    ")\n",
    "\n",
    "model_size_model_stem = path.join(model_dir, \"sobol_reg_model_size\")\n",
    "model_size_results = rfr_group_mae(\n",
    "    X_array_model_size,\n",
    "    y_array_model_size,\n",
    "    sobol_reg_model_size_group,\n",
    "    model_size_model_stem,\n",
    "    \"model_size\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for runtime: 20.5904 +/- 1.0632\n"
     ]
    }
   ],
   "source": [
    "runtime_features = common_features + [\"runtime_rank\"]\n",
    "\n",
    "X_array_runtime = sobol_reg[runtime_features].to_numpy()\n",
    "y_array_runtime = sobol_reg[[\"runtime\"]].to_numpy().ravel()\n",
    "\n",
    "sobol_reg_runtime_group = (\n",
    "    sobol_reg[common_features]\n",
    "    .round(6)\n",
    "    .apply(lambda row: \"_\".join(row.values.astype(str)), axis=1)\n",
    ")\n",
    "\n",
    "runtime_model_stem = path.join(model_dir, \"sobol_reg_runtime\")\n",
    "runtime_results = rfr_group_mae(\n",
    "    X_array_runtime,\n",
    "    y_array_runtime,\n",
    "    sobol_reg_runtime_group,\n",
    "    runtime_model_stem,\n",
    "    \"runtime\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_results = {\n",
    "    \"mae\": mae_results,\n",
    "    \"rmse\": rmse_results,\n",
    "    \"model_size\": model_size_results,\n",
    "    \"runtime\": runtime_results,\n",
    "}\n",
    "with open(path.join(data_dir, \"model_metadata.json\"), \"w\") as f:\n",
    "    json.dump(main_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': RandomForestRegressor(random_state=13),\n",
       " 'rmse': RandomForestRegressor(random_state=13),\n",
       " 'model_size': RandomForestRegressor(random_state=13),\n",
       " 'runtime': RandomForestRegressor(random_state=13)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_paths = {\n",
    "    \"mae\": mae_model_stem,\n",
    "    \"rmse\": rmse_model_stem,\n",
    "    \"model_size\": model_size_model_stem,\n",
    "    \"runtime\": runtime_model_stem,\n",
    "}\n",
    "for i in range(5):\n",
    "    models = {}\n",
    "    for key, model_path in model_paths.items():\n",
    "        models[key] = joblib.load(f\"{model_path}_{i}.pkl\")\n",
    "\n",
    "    with open(path.join(cv_model_dir, f\"cross_validation_models_{i}.pkl\"), \"wb\") as f:\n",
    "        joblib.dump(models, f, compress=7)\n",
    "\n",
    "models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production models (full training data)\n",
    "Six keys in the dictionary, each key is a value of a label, and its value pair is the trained model.\n",
    "This trained model is stored in the models folder with the pickle file name \"trained_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(\n",
    "    sr_feat_array,\n",
    "    sr_labels_array,\n",
    "    sr_label_names,\n",
    "):\n",
    "    models = {}\n",
    "\n",
    "    for X1, y1, name1 in zip(sr_feat_array, sr_labels_array, sr_label_names):\n",
    "        print(f\"X1 sr shape: {X1.shape}, Y1 sr shape: {y1.shape}\")\n",
    "        model = RandomForestRegressor(random_state=13)\n",
    "        model.fit(X1, y1)\n",
    "        models[name1] = model\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 sr shape: (173219, 29), Y1 sr shape: (173219,)\n",
      "X1 sr shape: (173219, 29), Y1 sr shape: (173219,)\n",
      "X1 sr shape: (173219, 28), Y1 sr shape: (173219,)\n",
      "X1 sr shape: (173219, 29), Y1 sr shape: (173219,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['..\\\\..\\\\models\\\\crabnet_hyperparameter\\\\surrogate_models.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of x_arrays, y_arrays, and target_names\n",
    "sobol_reg_x_arrays = [X_array_mae, X_array_rmse, X_array_model_size, X_array_runtime]\n",
    "sobol_reg_labels = [y_array_mae, y_array_rmse, y_array_model_size, y_array_runtime]\n",
    "sobol_reg_target_names = [\"mae\", \"rmse\", \"model_size\", \"runtime\"]\n",
    "\n",
    "# Train and save the model on all the data\n",
    "models = train_and_save(\n",
    "    sobol_reg_x_arrays,\n",
    "    sobol_reg_labels,\n",
    "    sobol_reg_target_names,\n",
    ")\n",
    "\n",
    "joblib.dump(models, path.join(model_dir, \"surrogate_models.pkl\"), compress=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matsci-opt-benchmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01883adffc5ff99e80740fdb2688c7d7f1b5220f2274814f600fbe3b3887f376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
